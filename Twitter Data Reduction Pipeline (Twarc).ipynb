{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "careful-columbia",
   "metadata": {},
   "source": [
    "## Tweet Reduction Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-completion",
   "metadata": {},
   "source": [
    "This is a data reduction pipeline for tweets generated from **tweet Ids**.\n",
    "You can obtain millions of 2020 Covid-19 tweet Ids from this website https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/LW0BTB. <g>You are free to check other websites that can provide you with tweet Id on your topic of interest<g>. Once obtained, the tweet Ids can be used to retrieve the corresponding tweets with extra information by using the **twarc library**. A documentation on how to install, configure and use twarc can be found here https://scholarslab.github.io/learn-twarc/06-twarc-command-basics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-longitude",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<b>!! Attention !!</b> High number of tweet Ids can results into 10s of GB of data. Ensure you have enough storage space and first Internet speed.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-worse",
   "metadata": {},
   "source": [
    "First, we begin by importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "removable-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-material",
   "metadata": {},
   "source": [
    "We have obatined our twitter Ids from the following website https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/LW0BTB. These are just Ids that can be used to generate the corresponding tweets using **twarc** library function known as hydrate. The Process of generating the corresponding tweets is known as **hydrating**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-fortune",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<b>!! Attention !!</b> This is a memory intensive task. For instance, it took 13 hours for a 6GB GPU computer with a 10Mbps Internet speed connection. The higher the Internet speed, the faster the process.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-pressure",
   "metadata": {},
   "source": [
    "This can be done in linux-based systems' **terminal** or windows' **command**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!twarc hydrate tweets_id2.txt > full_tweets2.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-fancy",
   "metadata": {},
   "source": [
    "The resulting file can be very huge (20GB) depending on how many tweet Ids you hydrated and cannot be read directly by the computer due to memory limitation. Therefore we split them in terminal into 100000 lines each using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "convertible-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!split -l 100000 full_tweets1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-motel",
   "metadata": {},
   "source": [
    "The following code is for renaming the resultant splitted individual files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "labeled-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/makavelli/Documents/TUK/DARA Big Data/retweetsNo/'\n",
    "files = os.listdir(path)\n",
    "i = 1\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "    os.rename(os.path.join(path, file), os.path.join(path, ''.join([str(index), '.csv'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-spain",
   "metadata": {},
   "source": [
    "We now read each of the json files, create new dataframes with selected columns of interest and save them as CSV files in a folder called CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "developing-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/makavelli/Documents/TUK/DARA Big Data/files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-wrist",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> You need to manually create the **'CSV'** folder in your working directory.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complex-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 15s, sys: 38.2 s, total: 12min 53s\n",
      "Wall time: 13min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lists = os.listdir('/home/makavelli/Documents/TUK/DARA Big Data/files/') #Where to read files from\n",
    "files = len(lists) #Count the number of files and return it as interger to be used in the loop\n",
    "path1 = '/home/makavelli/Documents/TUK/DARA Big Data/CSV/'#Where to store the resulting files\n",
    "for i in range(files):\n",
    "    try:\n",
    "        df = pd.read_json(path+str(i)+\".json\",lines=True)\n",
    "        df1 =df[['created_at','full_text','user','lang']] #specify the twitter data column that you want to use\n",
    "        df1.to_csv(path1+str(i)+'.csv',)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-round",
   "metadata": {},
   "source": [
    "We now read the saved CSV files and remove tweets that are not in English and then save them in a folder called \"langreduced\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-lemon",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> You need to manually create the **'langreduced'** in your working directory.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prospective-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 3.77 s, total: 1min 22s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lists = os.listdir('/home/makavelli/Documents/TUK/DARA Big Data/CSV/') #Where to read files from\n",
    "files = len(lists) #Count the number of files and return it as interger to be used in the loop\n",
    "path2 = '/home/makavelli/Documents/TUK/DARA Big Data/langreduced/'#Where to store the resulting files\n",
    "for i in range(files):\n",
    "    try:\n",
    "        df2 = pd.read_csv(path1+str(i)+'.csv')\n",
    "        df3 = df2[df2['lang']=='en']\n",
    "        df3.to_csv(path2+str(i)+'.csv',index=False)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-cable",
   "metadata": {},
   "source": [
    "In order to ensure that our data is free of redundancy, we need to remove any retweets as they might compromise the quality.\n",
    "We now create new column labelled \"Retweet\" in each of the csv files and store them in a new directory called \"retweetFree\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-salem",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> You need to manually create the **'retweetFree'** folder in your working directory.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exterior-japan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 2.94 s, total: 1min 9s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lists = os.listdir('/home/makavelli/Documents/TUK/DARA Big Data/langreduced/') #Where to read files from\n",
    "files = len(lists)#Count the number of files and return it as interger to be used in the loop\n",
    "path3 = '/home/makavelli/Documents/TUK/DARA Big Data/retweetFree/'#Where to store the resulting files\n",
    "for i in range(files):\n",
    "    try:\n",
    "        df4 = pd.read_csv(path2+str(i)+'.csv')\n",
    "        df4['Retweet']=\"\"\n",
    "        df5 = df4.to_csv(path3+str(i)+'.csv',index=False)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-junction",
   "metadata": {},
   "source": [
    "We now create a loop that will read through all the csv files in path3, count the rows and assign *'Yes'* or *'No'* to the newly created column, **'Retweets'** if the **full_text** column as any word, *'RT @'*. We then select only the rows with *'No'* and save the corresponding dataframe to the folder known as *'retweetsNo'*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-reporter",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> You need to manually create the **'retweetNo'** folder in your working directory.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fabulous-willow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 48s, sys: 6.34 s, total: 15min 55s\n",
      "Wall time: 15min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path4 = '/home/makavelli/Documents/TUK/DARA Big Data/retweetsNo/' #path to store results\n",
    "lists = os.listdir(path3) #Create a variable to store the number of files\n",
    "files = len(lists) #Create a variable to return the number of files as interger to be used in the loop\n",
    "for i in range(files):\n",
    "    try:\n",
    "        df6 = pd.read_csv(path3+str(i)+'.csv') #read the files in path3\n",
    "        rows = df6.shape[0]          #Count the number of rows in each dataframe to use in the subsequent loop\n",
    "        for k in range(rows):\n",
    "            if str('RT @') in str(df6['full_text'].loc[k]):#check for tweets with RT @\n",
    "                df6['Retweet'].loc[k]='Yes' #Assign 'Yes' to tweets with RT @\n",
    "            else:\n",
    "                df6['Retweet'].loc[k]='No' #Assign 'No' to tweets without RT @\n",
    "        df6=df6[df6.Retweet=='No'] #Create new dataframes for tweets without retweets\n",
    "        df7 = df6.to_csv(path4+str(i)+'.csv',index=False) #save the dataframes as csv files to path4\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-negative",
   "metadata": {},
   "source": [
    "We then confirm if all retweets have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decimal-multiple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>user</th>\n",
       "      <th>lang</th>\n",
       "      <th>Retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2020-03-03 17:47:49+00:00</td>\n",
       "      <td>CORNAVIRUS FULL STORY : WATCH HERE : https://t...</td>\n",
       "      <td>{'id': 1167737750075764741, 'id_str': '1167737...</td>\n",
       "      <td>en</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2020-03-03 17:47:49+00:00</td>\n",
       "      <td>A bit bungling this from Boris.\\nBut far worse...</td>\n",
       "      <td>{'id': 43730789, 'id_str': '43730789', 'name':...</td>\n",
       "      <td>en</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>2020-03-03 17:47:49+00:00</td>\n",
       "      <td>Donâ€™t be panic, just be careful about corona v...</td>\n",
       "      <td>{'id': 372364297, 'id_str': '372364297', 'name...</td>\n",
       "      <td>en</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2020-03-03 17:47:50+00:00</td>\n",
       "      <td>'The pope is dead',\\n\\n In the HBO tv show a v...</td>\n",
       "      <td>{'id': 1137155780342439936, 'id_str': '1137155...</td>\n",
       "      <td>en</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>2020-03-03 17:47:50+00:00</td>\n",
       "      <td>Breaking: #CoronaOutbreak has killed 6 more pe...</td>\n",
       "      <td>{'id': 20420845, 'id_str': '20420845', 'name':...</td>\n",
       "      <td>en</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11803</th>\n",
       "      <td>99924</td>\n",
       "      <td>2020-03-03 19:15:44+00:00</td>\n",
       "      <td>@DrTedros @WHO @Twitter We wish and pray to Go...</td>\n",
       "      <td>{'id': 1221856187660099588, 'id_str': '1221856...</td>\n",
       "      <td>en</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11804</th>\n",
       "      <td>99938</td>\n",
       "      <td>2020-03-03 19:15:45+00:00</td>\n",
       "      <td>ðŸ˜”ðŸ’”ðŸ’”ðŸ’”ðŸ’”ðŸ’” Prayers aren't going to help us. Our ad...</td>\n",
       "      <td>{'id': 2796385418, 'id_str': '2796385418', 'na...</td>\n",
       "      <td>en</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805</th>\n",
       "      <td>99961</td>\n",
       "      <td>2020-03-03 19:15:46+00:00</td>\n",
       "      <td>Stephanie Grisham' Mr President '\\nDonald J. T...</td>\n",
       "      <td>{'id': 345676271, 'id_str': '345676271', 'name...</td>\n",
       "      <td>en</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11806</th>\n",
       "      <td>99985</td>\n",
       "      <td>2020-03-03 19:15:47+00:00</td>\n",
       "      <td>7th person confirmed to have died in relation ...</td>\n",
       "      <td>{'id': 12137172, 'id_str': '12137172', 'name':...</td>\n",
       "      <td>en</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11807</th>\n",
       "      <td>99998</td>\n",
       "      <td>2020-03-03 19:15:47+00:00</td>\n",
       "      <td>Pre-save my new single \"Trump Virus\" on Spotif...</td>\n",
       "      <td>{'id': 813932760, 'id_str': '813932760', 'name...</td>\n",
       "      <td>en</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11808 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                 created_at  \\\n",
       "0               9  2020-03-03 17:47:49+00:00   \n",
       "1              10  2020-03-03 17:47:49+00:00   \n",
       "2              14  2020-03-03 17:47:49+00:00   \n",
       "3              16  2020-03-03 17:47:50+00:00   \n",
       "4              30  2020-03-03 17:47:50+00:00   \n",
       "...           ...                        ...   \n",
       "11803       99924  2020-03-03 19:15:44+00:00   \n",
       "11804       99938  2020-03-03 19:15:45+00:00   \n",
       "11805       99961  2020-03-03 19:15:46+00:00   \n",
       "11806       99985  2020-03-03 19:15:47+00:00   \n",
       "11807       99998  2020-03-03 19:15:47+00:00   \n",
       "\n",
       "                                               full_text  \\\n",
       "0      CORNAVIRUS FULL STORY : WATCH HERE : https://t...   \n",
       "1      A bit bungling this from Boris.\\nBut far worse...   \n",
       "2      Donâ€™t be panic, just be careful about corona v...   \n",
       "3      'The pope is dead',\\n\\n In the HBO tv show a v...   \n",
       "4      Breaking: #CoronaOutbreak has killed 6 more pe...   \n",
       "...                                                  ...   \n",
       "11803  @DrTedros @WHO @Twitter We wish and pray to Go...   \n",
       "11804  ðŸ˜”ðŸ’”ðŸ’”ðŸ’”ðŸ’”ðŸ’” Prayers aren't going to help us. Our ad...   \n",
       "11805  Stephanie Grisham' Mr President '\\nDonald J. T...   \n",
       "11806  7th person confirmed to have died in relation ...   \n",
       "11807  Pre-save my new single \"Trump Virus\" on Spotif...   \n",
       "\n",
       "                                                    user lang Retweet  \n",
       "0      {'id': 1167737750075764741, 'id_str': '1167737...   en      No  \n",
       "1      {'id': 43730789, 'id_str': '43730789', 'name':...   en      No  \n",
       "2      {'id': 372364297, 'id_str': '372364297', 'name...   en      No  \n",
       "3      {'id': 1137155780342439936, 'id_str': '1137155...   en      No  \n",
       "4      {'id': 20420845, 'id_str': '20420845', 'name':...   en      No  \n",
       "...                                                  ...  ...     ...  \n",
       "11803  {'id': 1221856187660099588, 'id_str': '1221856...   en      No  \n",
       "11804  {'id': 2796385418, 'id_str': '2796385418', 'na...   en      No  \n",
       "11805  {'id': 345676271, 'id_str': '345676271', 'name...   en      No  \n",
       "11806  {'id': 12137172, 'id_str': '12137172', 'name':...   en      No  \n",
       "11807  {'id': 813932760, 'id_str': '813932760', 'name...   en      No  \n",
       "\n",
       "[11808 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8 = pd.read_csv(path4+'1.csv')\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "alpine-cartridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total remaining tweets are 525174 tweets\n"
     ]
    }
   ],
   "source": [
    "lists = os.listdir(path4) \n",
    "files = len(lists)\n",
    "tot=0\n",
    "for i in range(files):\n",
    "    try:\n",
    "        df8 = pd.read_csv(path4+str(i)+'.csv')\n",
    "        rows = df8.shape[0]\n",
    "        tot += rows\n",
    "    except:\n",
    "        pass\n",
    "print('The total remaining tweets are '+str(tot)+' tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-merchant",
   "metadata": {},
   "source": [
    "Your data can now be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-prison",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-butter",
   "metadata": {},
   "source": [
    "The following code lines will help in renaming the downloaded files numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'specificy path here/'\n",
    "files = os.listdir(path)\n",
    "i = 1\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "    os.rename(os.path.join(path, file), os.path.join(path, ''.join([str(index), '.csv'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
